import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score
import openpyxl
import os
import base64
from github import Github, InputGitTreeElement
import io
import time

# é…ç½®é¡µé¢
st.set_page_config(
    layout="wide",
    page_title="Pharmaceutical Formulation Analysis",
    page_icon="ğŸ§ª"
)

# å…¨å±€å˜é‡
GITHUB_REPO = "Sharry2025/suspensions"  # æ ¼å¼ï¼šç”¨æˆ·å/ä»“åº“å
DATA_FILE = "data.xlsx"   # ä»“åº“ä¸­çš„æ–‡ä»¶å
TARGET_COL = "F40"
FEATURES = [
    "Sulfadiazine (g)", "Glycerol (ml)", "Tragacanth gum (g)", 
    "CMC-Na (g)", "sodium citrate (g)", "Purified water (ml)"
]

# åˆå§‹åŒ–GitHub APIï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
@st.cache_resource
def get_github_client():
    """åˆå§‹åŒ–GitHubå®¢æˆ·ç«¯ï¼ŒåŒ…å«è¯¦ç»†çš„é”™è¯¯å¤„ç†"""
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨Token
    if "GITHUB_TOKEN" not in st.secrets:
        st.error("""
        âŒ GitHub Tokenæœªé…ç½®ï¼è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
        1. è®¿é—® [GitHub Tokenè®¾ç½®](https://github.com/settings/tokens) ç”Ÿæˆæ–°Tokenï¼ˆéœ€repoæƒé™ï¼‰
        2. åœ¨Streamlit Cloudçš„Settings â†’ Secretsä¸­æ·»åŠ ï¼š
           ```toml
           [secrets]
           GITHUB_TOKEN = "ä½ çš„Token"
           ```
        """, icon="âš ï¸")
        return None
    
    try:
        # æµ‹è¯•Tokenæœ‰æ•ˆæ€§
        g = Github(st.secrets["GITHUB_TOKEN"])
        test_repo = g.get_repo(GITHUB_REPO)  # æµ‹è¯•ä»“åº“è®¿é—®æƒé™
        return g
    except ImportError:
        st.error("""
        âŒ ç¼ºå°‘PyGithubåº“ï¼è¯·åœ¨requirements.txtä¸­æ·»åŠ ï¼š
        ```text
        PyGithub>=1.55
        ```
        """, icon="ğŸ› ï¸")
    except Exception as e:
        error_msg = str(e)
        if "Bad credentials" in error_msg:
            st.error("âŒ Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸï¼è¯·é‡æ–°ç”ŸæˆToken", icon="ğŸ”‘")
        elif "Not Found" in error_msg:
            st.error(f"âŒ ä»“åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®ï¼š{GITHUB_REPO}", icon="ğŸ“‚")
        else:
            st.error(f"âŒ GitHubè¿æ¥å¤±è´¥ï¼š{error_msg}", icon="ğŸš¨")
    return None

# æ•°æ®åŠ è½½ï¼ˆå¸¦ç¼“å­˜å’Œé‡è¯•æœºåˆ¶ï¼‰
@st.cache_data(ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
def load_data(max_retries=3):
    """ä»GitHubåŠ è½½æ•°æ®ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            raw_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/{DATA_FILE}"
            df = pd.read_excel(raw_url, engine='openpyxl')
            if df.empty:
                st.warning("âš ï¸ æ•°æ®æ–‡ä»¶ä¸ºç©ºï¼Œæ­£åœ¨åˆ›å»ºæ–°æ•°æ®æ¡†æ¶")
                return pd.DataFrame(columns=FEATURES + [TARGET_COL])
            return df.dropna()
        except Exception as e:
            if attempt == max_retries - 1:
                st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼ˆæœ€ç»ˆå°è¯•ï¼‰ï¼š{str(e)}", icon="ğŸš¨")
                return pd.DataFrame(columns=FEATURES + [TARGET_COL])
            time.sleep(2)  # å»¶è¿Ÿé‡è¯•

# ä¿å­˜æ•°æ®åˆ°GitHubï¼ˆå¢å¼ºç‰ˆï¼‰
def save_to_github(df):
    """ä¿å­˜æ•°æ®åˆ°GitHubä»“åº“ï¼ŒåŒ…å«å®Œæ•´äº‹åŠ¡å¤„ç†"""
    if df.empty:
        st.error("âŒ ä¸èƒ½ä¿å­˜ç©ºæ•°æ®", icon="ğŸ“­")
        return False
    
    try:
        g = get_github_client()
        if not g:
            return False
        
        with st.spinner("ğŸš€ æ­£åœ¨ä¿å­˜åˆ°GitHub..."):
            repo = g.get_repo(GITHUB_REPO)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            try:
                contents = repo.get_contents(DATA_FILE)
                sha = contents.sha
                action = "æ›´æ–°"
            except:
                sha = None
                action = "åˆ›å»º"
            
            # ç”ŸæˆExcelæ–‡ä»¶
            output = io.BytesIO()
            df.to_excel(output, index=False, engine='openpyxl')
            excel_data = output.getvalue()
            
            # æäº¤æ›´æ”¹
            repo.update_file(
                path=DATA_FILE,
                message=f"{action} {DATA_FILE} (æ¥è‡ªStreamlitåº”ç”¨)",
                content=excel_data,
                sha=sha
            )
            
            st.toast(f"âœ… æ•°æ®å·²æˆåŠŸ{action}åˆ°GitHubï¼", icon="âœ…")
            return True
            
    except Exception as e:
        error_msg = str(e)
        if "This repository is empty" in error_msg:
            st.error("âŒ ç›®æ ‡ä»“åº“ä¸ºç©ºï¼Œè¯·å…ˆæäº¤ä¸€ä¸ªåˆå§‹æ–‡ä»¶", icon="ğŸ“¦")
        elif "large files" in error_msg:
            st.error("âŒ æ–‡ä»¶è¿‡å¤§ï¼Œè¯·å‡å°æ•°æ®è§„æ¨¡", icon="ğŸ“")
        else:
            st.error(f"âŒ ä¿å­˜å¤±è´¥ï¼š{error_msg}", icon="ğŸš¨")
        return False

# æ¨¡å‹è®­ç»ƒï¼ˆä¼˜åŒ–ç‰ˆï¼‰
@st.cache_resource(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def train_model():
    """è®­ç»ƒæ¨¡å‹ï¼Œå¸¦æ•°æ®é‡æ£€æŸ¥"""
    df = load_data()
    if len(df) < 10:
        st.warning("âš ï¸ è‡³å°‘éœ€è¦10æ¡æ•°æ®æ‰èƒ½è®­ç»ƒæ¨¡å‹", icon="ğŸ“‰")
        return None
    
    try:
        X = df[FEATURES]
        y = df[TARGET_COL]
        
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=5,
            random_state=42,
            n_jobs=-1
        )
        
        param_grid = {
            'n_estimators': [50, 100, 150],
            'max_depth': [3, 5, 7]
        }
        
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            cv=5,
            scoring='r2'
        )
        
        with st.spinner("ğŸ¤– æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
            grid_search.fit(X, y)
        
        return grid_search.best_estimator_
        
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}", icon="âš™ï¸")
        return None

# ç•Œé¢1: æ•°æ®åˆ†æï¼ˆä¼˜åŒ–ç‰ˆï¼‰
def show_data_analysis():
    st.header("ğŸ“Š æ•°æ®åˆ†æ", divider="rainbow")
    df = load_data()
    
    if len(df) < 3:
        st.warning("âš ï¸ è‡³å°‘éœ€è¦3æ¡æ•°æ®è¿›è¡Œåˆ†æ", icon="ğŸ“Š")
        return
    
    with st.expander("ğŸ“‚ æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=True):
        st.dataframe(df, use_container_width=True)
    
    st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æ")
    try:
        corr_matrix = df.corr().round(2)
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
        st.pyplot(fig)
    except Exception as e:
        st.error(f"âŒ ç›¸å…³æ€§åˆ†æå¤±è´¥ï¼š{str(e)}", icon="ğŸ“ˆ")
    
    model = train_model()
    if model:
        st.subheader("ğŸ¤– æ¨¡å‹ä¿¡æ¯")
        
        tab1, tab2 = st.tabs(["ç‰¹å¾é‡è¦æ€§", "æ¨¡å‹æ€§èƒ½"])
        
        with tab1:
            importance_df = pd.DataFrame({
                "ç‰¹å¾": FEATURES,
                "é‡è¦æ€§": model.feature_importances_
            }).sort_values("é‡è¦æ€§", ascending=False)
            
            st.dataframe(
                importance_df,
                column_config={
                    "ç‰¹å¾": st.column_config.TextColumn(width="medium"),
                    "é‡è¦æ€§": st.column_config.ProgressColumn(
                        min_value=0,
                        max_value=float(importance_df["é‡è¦æ€§"].max()),
                },
                hide_index=True,
                use_container_width=True
            )
        
        with tab2:
            predictions = model.predict(df[FEATURES])
            r2 = r2_score(df[TARGET_COL], predictions)
            
            col1, col2 = st.columns(2)
            col1.metric("RÂ² åˆ†æ•°", f"{r2:.4f}")
            
            fig, ax = plt.subplots()
            ax.scatter(df[TARGET_COL], predictions, alpha=0.6)
            ax.plot([0, 1], [0, 1], 'r--')
            ax.set_xlabel("å®é™…å€¼")
            ax.set_ylabel("é¢„æµ‹å€¼")
            col2.pyplot(fig)

# ç•Œé¢2: æ•°æ®ç®¡ç†ï¼ˆå®Œæ•´ç‰ˆï¼‰
def show_data_management():
    st.header("ğŸ“ æ•°æ®ç®¡ç†", divider="rainbow")
    df = load_data()
    
    # æ·»åŠ æ–°æ•°æ®
    with st.expander("â• æ·»åŠ æ–°æ•°æ®", expanded=True):
        new_data = {}
        cols = st.columns(3)
        for i, col in enumerate(FEATURES):
            new_data[col] = cols[i%3].number_input(
                col,
                value=0.0,
                key=f"input_{col}",
                help=f"è¾“å…¥ {col} çš„å€¼"
            )
        new_data[TARGET_COL] = st.number_input(
            TARGET_COL,
            value=0.0,
            key="input_F40",
            help="è¾“å…¥ç›®æ ‡å€¼"
        )
        
        if st.button("æ·»åŠ æ•°æ®", type="primary"):
            new_df = pd.DataFrame([new_data])
            df = pd.concat([df, new_df], ignore_index=True)
            st.success("âœ… æ•°æ®å·²æš‚å­˜åˆ°æœ¬åœ°ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹ä¿å­˜åˆ°GitHub")
    
    # æ•°æ®ç¼–è¾‘ä¸åˆ é™¤
    with st.expander("âœï¸ ç¼–è¾‘ç°æœ‰æ•°æ®", expanded=True):
        st.write("å‹¾é€‰è¦åˆ é™¤çš„è¡Œï¼š")
        df_with_checkbox = df.copy()
        df_with_checkbox.insert(0, "é€‰æ‹©", False)
        
        edited_df = st.data_editor(
            df_with_checkbox,
            column_config={
                "é€‰æ‹©": st.column_config.CheckboxColumn(
                    "é€‰æ‹©",
                    help="é€‰æ‹©è¦åˆ é™¤çš„è¡Œ",
                    default=False
                )
            },
            hide_index=True,
            use_container_width=True,
            key="data_editor"
        )
        
        if st.button("åˆ é™¤é€‰å®šè¡Œ", type="secondary"):
            selected_rows = edited_df[edited_df["é€‰æ‹©"]]
            if not selected_rows.empty:
                df = df.drop(selected_rows.index)
                st.success(f"âœ… å·²æ ‡è®°åˆ é™¤ {len(selected_rows)} è¡Œï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹ä¿å­˜åˆ°GitHub")
            else:
                st.warning("âš ï¸ æœªé€‰æ‹©ä»»ä½•è¡Œ")
    
    # ä¿å­˜æ“ä½œ
    st.divider()
    if st.button("ğŸ’¾ ä¿å­˜åˆ°GitHub", type="primary", use_container_width=True):
        if save_to_github(df):
            st.cache_data.clear()  # æ¸…é™¤æ•°æ®ç¼“å­˜
            st.cache_resource.clear()  # æ¸…é™¤æ¨¡å‹ç¼“å­˜
            time.sleep(1)
            st.rerun()

# ç•Œé¢3: F40é¢„æµ‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
def show_prediction():
    st.header("ğŸ”® F40é¢„æµ‹", divider="rainbow")
    model = train_model()
    
    if not model:
        st.warning("âš ï¸ æ¨¡å‹æœªè®­ç»ƒï¼ˆéœ€è¦è‡³å°‘10æ¡æ•°æ®ï¼‰", icon="ğŸ¤–")
        return
    
    st.subheader("ğŸ“¥ è¾“å…¥å‚æ•°")
    input_data = {}
    cols = st.columns(3)
    for i, col in enumerate(FEATURES):
        input_data[col] = cols[i%3].number_input(
            col,
            value=0.0,
            min_value=0.0,
            step=0.1,
            key=f"pred_{col}"
        )
    
    if st.button("é¢„æµ‹F40", type="primary"):
        with st.spinner("ğŸ”® æ­£åœ¨é¢„æµ‹..."):
            input_df = pd.DataFrame([input_data])
            try:
                prediction = np.clip(model.predict(input_df)[0], 0, 1)
                
                st.subheader("ğŸ“¤ é¢„æµ‹ç»“æœ")
                st.metric(
                    label="é¢„æµ‹å€¼",
                    value=f"{prediction:.4f}",
                    help="F40é¢„æµ‹å€¼ï¼ˆ0-1èŒƒå›´ï¼‰"
                )
                
                st.subheader("ğŸ“Š ç‰¹å¾è´¡çŒ®åº¦")
                contributions = model.feature_importances_ * input_df.values[0]
                contrib_df = pd.DataFrame({
                    "ç‰¹å¾": FEATURES,
                    "è´¡çŒ®å€¼": contributions,
                    "è´¡çŒ®ç™¾åˆ†æ¯”": 100 * np.abs(contributions) / np.sum(np.abs(contributions))
                }).sort_values("è´¡çŒ®ç™¾åˆ†æ¯”", ascending=False)
                
                st.dataframe(
                    contrib_df,
                    column_config={
                        "è´¡çŒ®ç™¾åˆ†æ¯”": st.column_config.ProgressColumn(
                            format="%.1f%%",
                            min_value=0,
                            max_value=100
                        )
                    },
                    hide_index=True,
                    use_container_width=True
                )
                
            except Exception as e:
                st.error(f"âŒ é¢„æµ‹å¤±è´¥ï¼š{str(e)}", icon="ğŸš¨")

# ä¸»ç•Œé¢
def main():
    st.sidebar.title("å¯¼èˆª")
    with st.sidebar:
        st.image("https://streamlit.io/images/brand/streamlit-mark-color.png", width=50)
        page = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["æ•°æ®åˆ†æ", "æ•°æ®ç®¡ç†", "F40é¢„æµ‹"],
            index=0,
            label_visibility="collapsed"
        )
    
    if page == "æ•°æ®åˆ†æ":
        show_data_analysis()
    elif page == "æ•°æ®ç®¡ç†":
        show_data_management()
    elif page == "F40é¢„æµ‹":
        show_prediction()

    # é¡µè„š
    st.sidebar.divider()
    st.sidebar.caption(f"æœ€åæ›´æ–°ï¼š{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")

if __name__ == "__main__":
    main()
