import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score
import openpyxl
import os
import base64
from github import Github, InputGitTreeElement
import io

# é…ç½®é¡µé¢
st.set_page_config(layout="wide", page_title="Pharmaceutical Formulation Analysis")

# å…¨å±€å˜é‡
GITHUB_REPO = "Sharry2025/suspensions"  # æ ¼å¼ï¼šç”¨æˆ·å/ä»“åº“å
DATA_FILE = "data.xlsx"   # ä»“åº“ä¸­çš„æ–‡ä»¶å
TARGET_COL = "F40"
FEATURES = [
    "Sulfadiazine (g)", "Glycerol (ml)", "Tragacanth gum (g)", 
    "CMC-Na (g)", "sodium citrate (g)", "Purified water (ml)"
]

# åˆå§‹åŒ–GitHub APIï¼ˆä»Streamlit Secretsè·å–Tokenï¼‰
@st.cache_resource
def get_github_client():
    try:
        token = st.secrets["GITHUB_TOKEN"]
        return Github(token)
    except Exception as e:
        st.error(f"GitHub APIåˆå§‹åŒ–å¤±è´¥: {e}")
        return None

# æ•°æ®åŠ è½½ï¼ˆä»GitHub Raw URLï¼‰
@st.cache_data
def load_data():
    try:
        raw_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/{DATA_FILE}"
        df = pd.read_excel(raw_url, engine='openpyxl')
        return df.dropna()
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        cols = FEATURES + [TARGET_COL]
        return pd.DataFrame(columns=cols)

# ä¿å­˜æ•°æ®åˆ°GitHub
def save_to_github(df):
    try:
        g = get_github_client()
        if not g:
            return False
        
        repo = g.get_repo(GITHUB_REPO)
        contents = repo.get_contents(DATA_FILE)  # è·å–æ–‡ä»¶å½“å‰å†…å®¹
        
        # å°†DataFrameè½¬æ¢ä¸ºExceläºŒè¿›åˆ¶æ•°æ®
        output = io.BytesIO()
        df.to_excel(output, index=False, engine='openpyxl')
        excel_data = output.getvalue()
        
        # æ›´æ–°æ–‡ä»¶
        repo.update_file(
            path=DATA_FILE,
            message="Update data.xlsx via Streamlit App",
            content=excel_data,
            sha=contents.sha
        )
        return True
    except Exception as e:
        st.error(f"ä¿å­˜åˆ°GitHubå¤±è´¥: {e}")
        return False

# æ¨¡å‹è®­ç»ƒï¼ˆä¿æŒä¸å˜ï¼‰
@st.cache_resource
def train_model():
    df = load_data()
    if len(df) < 10:
        st.warning("è‡³å°‘éœ€è¦10æ¡æ•°æ®è®­ç»ƒæ¨¡å‹")
        return None
    
    X = df[FEATURES]
    y = df[TARGET_COL]
    
    model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
    param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7]}
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X, y)
    return grid_search.best_estimator_

# ç•Œé¢1: æ•°æ®åˆ†æï¼ˆä¿æŒä¸å˜ï¼‰
def show_data_analysis():
    st.header("ğŸ“Š Data Analysis")
    df = load_data()
    
    if len(df) < 3:
        st.warning("è‡³å°‘éœ€è¦3æ¡æ•°æ®è¿›è¡Œåˆ†æ")
        return
    
    with st.expander("View Raw Data"):
        st.dataframe(df)
    
    st.subheader("Correlation Analysis")
    corr_matrix = df.corr().round(2)
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
    st.pyplot(fig)
    
    model = train_model()
    if model:
        st.subheader("Model Information")
        importance_df = pd.DataFrame({
            "Feature": FEATURES,
            "Importance": model.feature_importances_
        }).sort_values("Importance", ascending=False)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Feature Importance:**")
            st.dataframe(importance_df)
        
        with col2:
            predictions = model.predict(df[FEATURES])
            r2 = r2_score(df[TARGET_COL], predictions)
            st.markdown("**Model Performance:**")
            st.metric(label="RÂ² Score", value=f"{r2:.4f}")
            
            fig, ax = plt.subplots()
            ax.scatter(df[TARGET_COL], predictions)
            ax.plot([0, 1], [0, 1], 'r--')
            ax.set_xlabel("Actual F40")
            ax.set_ylabel("Predicted F40")
            st.pyplot(fig)

# ç•Œé¢2: æ•°æ®ç®¡ç†ï¼ˆæ–°å¢GitHubä¿å­˜åŠŸèƒ½ï¼‰
def show_data_management():
    st.header("ğŸ“ Data Management")
    df = load_data()
    
    # æ·»åŠ æ–°æ•°æ®
    st.subheader("Add New Data")
    new_data = {}
    cols = st.columns(3)
    for i, col in enumerate(FEATURES):
        new_data[col] = cols[i%3].number_input(col, value=0.0, key=f"input_{col}")
    new_data[TARGET_COL] = st.number_input(TARGET_COL, value=0.0, key="input_F40")
    
    if st.button("Add Data"):
        new_df = pd.DataFrame([new_data])
        df = pd.concat([df, new_df], ignore_index=True)
        st.success("æ•°æ®å·²æš‚å­˜ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¿å­˜åˆ°GitHubï¼")
    
    # æ•°æ®åˆ é™¤ä¸ä¿å­˜
    st.subheader("Manage Existing Data")
    df_with_checkbox = df.copy()
    df_with_checkbox.insert(0, "Select", False)
    
    edited_df = st.data_editor(
        df_with_checkbox,
        column_config={"Select": st.column_config.CheckboxColumn("Select", default=False)},
        hide_index=True,
        use_container_width=True
    )
    
    selected_rows = edited_df[edited_df["Select"]]
    if not selected_rows.empty and st.button("Delete Selected Rows"):
        df = df.drop(selected_rows.index)
        st.success("æ•°æ®å·²æš‚å­˜ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¿å­˜åˆ°GitHubï¼")
    
    # ä¿å­˜åˆ°GitHubæŒ‰é’®
    if st.button("ğŸ’¾ Save to GitHub", type="primary"):
        if save_to_github(df):
            st.success("æ•°æ®å·²æ›´æ–°åˆ°GitHubä»“åº“ï¼")
            st.cache_data.clear()  # æ¸…é™¤ç¼“å­˜ä»¥é‡æ–°åŠ è½½æ•°æ®
            st.rerun()
        else:
            st.error("ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥GitHub Tokenæˆ–ç½‘ç»œè¿æ¥ã€‚")

# ç•Œé¢3: F40é¢„æµ‹ï¼ˆä¿æŒä¸å˜ï¼‰
def show_prediction():
    st.header("ğŸ”® F40 Prediction")
    model = train_model()
    
    if not model:
        st.warning("æ¨¡å‹æœªè®­ç»ƒï¼ˆè‡³å°‘éœ€è¦10æ¡æ•°æ®ï¼‰")
        return
    
    st.subheader("Input Parameters")
    input_data = {}
    cols = st.columns(3)
    for i, col in enumerate(FEATURES):
        input_data[col] = cols[i%3].number_input(col, value=0.0, key=f"pred_{col}")
    
    if st.button("Predict F40"):
        input_df = pd.DataFrame([input_data])
        prediction = np.clip(model.predict(input_df)[0], 0, 1)
        st.subheader("Prediction Result")
        st.metric(label="Predicted F40", value=f"{prediction:.4f}")
        
        st.subheader("Feature Contributions")
        contributions = model.feature_importances_ * input_df.values[0]
        contrib_df = pd.DataFrame({
            "Feature": FEATURES,
            "Contribution": contributions,
            "Percentage": 100 * np.abs(contributions) / np.sum(np.abs(contributions))
        }).sort_values("Percentage", ascending=False)
        st.dataframe(contrib_df)

# ä¸»ç•Œé¢
def main():
    st.sidebar.title("Navigation")
    page = st.sidebar.radio("Go to", ["Data Analysis", "Data Management", "F40 Prediction"])
    
    if page == "Data Analysis":
        show_data_analysis()
    elif page == "Data Management":
        show_data_management()
    elif page == "F40 Prediction":
        show_prediction()

if __name__ == "__main__":
    main()
