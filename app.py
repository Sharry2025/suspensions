import streamlit as st

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.ensemble import RandomForestRegressor

from sklearn.model_selection import train_test_split, GridSearchCV

from sklearn.metrics import r2_score

import openpyxl

import os



# é…ç½®é¡µé¢

st.set_page_config(layout="wide", page_title="Pharmaceutical Formulation Analysis")



# å…¨å±€å˜é‡

DATA_PATH = "E:/suspensions/data.xlsx"

TARGET_COL = "F40"

FEATURES = [

    "Sulfadiazine (g)", "Glycerol (ml)", "Tragacanth gum (g)", 

    "CMC-Na (g)", "sodium citrate (g)", "Purified water (ml)"

]



# æ•°æ®åŠ è½½ä¸ä¿å­˜

@st.cache_data

def load_data():

    if os.path.exists(DATA_PATH):

        df = pd.read_excel(DATA_PATH, engine='openpyxl')

        return df.dropna()

    else:

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¸¦åˆ—åçš„ç©ºDataFrame

        cols = FEATURES + [TARGET_COL]

        return pd.DataFrame(columns=cols)



def save_data(df):

    df.to_excel(DATA_PATH, index=False, engine='openpyxl')



# æ¨¡å‹è®­ç»ƒ

@st.cache_resource

def train_model():

    df = load_data()

    if len(df) < 10:  # æ•°æ®é‡å¤ªå°‘æ—¶ä¸è®­ç»ƒæ¨¡å‹

        return None

    

    X = df[FEATURES]

    y = df[TARGET_COL]

    

    # ä½¿ç”¨éšæœºæ£®æ—å›å½’

    model = RandomForestRegressor(

        n_estimators=100,

        max_depth=5,

        random_state=42

    )

    

    # æ·»åŠ ç®€å•çš„å‚æ•°æœç´¢

    param_grid = {

        'n_estimators': [50, 100, 150],

        'max_depth': [3, 5, 7]

    }

    

    grid_search = GridSearchCV(

        estimator=model,

        param_grid=param_grid,

        cv=5,

        scoring='r2',

        n_jobs=-1

    )

    

    grid_search.fit(X, y)

    best_model = grid_search.best_estimator_

    

    return best_model



# ç•Œé¢1: æ•°æ®åˆ†æ

def show_data_analysis():

    st.header("ğŸ“Š Data Analysis")

    df = load_data()

    

    if len(df) < 3:

        st.warning("Not enough data for analysis (minimum 3 records required)")

        return

    

    # æ˜¾ç¤ºåŸå§‹æ•°æ®

    with st.expander("View Raw Data"):

        st.dataframe(df)

    

    # ç›¸å…³æ€§åˆ†æ

    st.subheader("Correlation Analysis")

    corr_matrix = df.corr().round(2)

    

    fig, ax = plt.subplots(figsize=(10, 8))

    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)

    st.pyplot(fig)

    

    # æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°

    model = train_model()

    if model:

        st.subheader("Model Information")

        

        # ç‰¹å¾é‡è¦æ€§

        importance_df = pd.DataFrame({

            "Feature": FEATURES,

            "Importance": model.feature_importances_

        }).sort_values("Importance", ascending=False)

        

        col1, col2 = st.columns(2)

        with col1:

            st.markdown("**Feature Importance:**")

            st.dataframe(importance_df)

        

        with col2:

            # è®¡ç®—RÂ²åˆ†æ•°

            predictions = model.predict(df[FEATURES])

            r2 = r2_score(df[TARGET_COL], predictions)

            st.markdown("**Model Performance:**")

            st.metric(label="RÂ² Score", value=f"{r2:.4f}")

            

            # ç»˜åˆ¶å®é™…vsé¢„æµ‹å€¼

            fig, ax = plt.subplots()

            ax.scatter(df[TARGET_COL], predictions)

            ax.plot([0, 1], [0, 1], 'r--')

            ax.set_xlabel("Actual F40")

            ax.set_ylabel("Predicted F40")

            st.pyplot(fig)



# ç•Œé¢2: æ•°æ®ç®¡ç†

def show_data_management():

    st.header("ğŸ“ Data Management")

    df = load_data()



    # æ·»åŠ æ–°æ•°æ®

    st.subheader("Add New Data")

    new_data = {}

    cols = st.columns(3)

    

    for i, col in enumerate(FEATURES):

        new_data[col] = cols[i%3].number_input(col, value=0.0, key=f"input_{col}")

    

    new_data[TARGET_COL] = st.number_input(TARGET_COL, value=0.0, key="input_F40")

    

    if st.button("Add Data"):

        new_df = pd.DataFrame([new_data])

        df = pd.concat([df, new_df], ignore_index=True)

        save_data(df)

        st.success("Data added successfully!")

        st.cache_data.clear()

        st.cache_resource.clear()

        st.rerun()

    

    # æ•°æ®åˆ é™¤åŠŸèƒ½

    st.subheader("Manage Existing Data")

    st.write("Select rows to delete:")

    

    df_with_checkbox = df.copy()

    df_with_checkbox.insert(0, "Select", False)

    

    edited_df = st.data_editor(

        df_with_checkbox,

        column_config={

            "Select": st.column_config.CheckboxColumn(

                "Select",

                help="Select rows to delete",

                default=False,

            )

        },

        hide_index=True,

        use_container_width=True

    )

    

    selected_rows = edited_df[edited_df["Select"]]

    

    if not selected_rows.empty and st.button("Delete Selected Rows"):

        df = df.drop(selected_rows.index)

        save_data(df)

        st.success(f"Deleted {len(selected_rows)} row(s)")

        st.cache_data.clear()

        st.cache_resource.clear()

        st.rerun()



# ç•Œé¢3: F40é¢„æµ‹

def show_prediction():

    st.header("ğŸ”® F40 Prediction")

    model = train_model()

    

    if not model:

        st.warning("Model not trained yet (need at least 10 records)")

        return

    

    # è¾“å…¥å‚æ•°

    st.subheader("Input Parameters")

    input_data = {}

    cols = st.columns(3)

    

    for i, col in enumerate(FEATURES):

        input_data[col] = cols[i%3].number_input(col, value=0.0, key=f"pred_{col}")

    

    # é¢„æµ‹

    if st.button("Predict F40"):

        input_df = pd.DataFrame([input_data])

        prediction = model.predict(input_df)[0]

        prediction = np.clip(prediction, 0, 1)  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…

        

        st.subheader("Prediction Result")

        st.metric(label="Predicted F40", value=f"{prediction:.4f}")

        

        # æ˜¾ç¤ºç‰¹å¾è´¡çŒ®

        st.subheader("Feature Contributions")

        contributions = model.feature_importances_ * input_df.values[0]

        contrib_df = pd.DataFrame({

            "Feature": FEATURES,

            "Contribution": contributions,

            "Percentage": 100 * np.abs(contributions) / np.sum(np.abs(contributions))

        }).sort_values("Percentage", ascending=False)

        

        st.dataframe(contrib_df)



# ä¸»ç•Œé¢

def main():

    st.sidebar.title("Navigation")

    page = st.sidebar.radio("Go to", ["Data Analysis", "Data Management", "F40 Prediction"])

    

    if page == "Data Analysis":

        show_data_analysis()

    elif page == "Data Management":

        show_data_management()

    elif page == "F40 Prediction":

        show_prediction()



if __name__ == "__main__":

    main()
